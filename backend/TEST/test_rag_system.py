#!/usr/bin/env python3
"""
Test script for RAG Answer Generation System
"""

import asyncio
import sys
import os
import json

# Add the backend directory to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from services.rag_answer_service import rag_answer_service
from models import GenerateResponseRequest

async def test_rag_system():
    """Test the RAG-based answer generation system."""
    print("ğŸ§ª Testing RAG Answer Generation System")
    print("=" * 60)
    
    # Test 1: Check service initialization
    print("\nğŸ”§ Testing Service Initialization...")
    print(f"âœ… Azure OpenAI configured: {rag_answer_service.openai_client is not None}")
    print(f"âœ… Qdrant configured: {rag_answer_service.qdrant_client is not None}")
    print(f"âœ… Embeddings configured: {rag_answer_service.embeddings is not None}")
    print(f"âœ… Collection name: {rag_answer_service.collection_name}")
    
    # Test 2: Search knowledge base
    print("\nğŸ” Testing Knowledge Base Search...")
    test_queries = [
        "What is your experience with similar projects?",
        "Please describe your proposed approach and methodology",
        "What is your team structure and key personnel?",
        "How do you ensure project quality and deliverables?"
    ]
    
    for query in test_queries:
        print(f"\nğŸ“‹ Query: {query}")
        try:
            results = await rag_answer_service.search_knowledge_base(
                query=query,
                top_k=3
            )
            
            print(f"   ğŸ“Š Results: {results['results_count']} chunks found")
            if results['chunks']:
                for i, chunk in enumerate(results['chunks'][:2], 1):
                    print(f"   ğŸ“„ Chunk {i}: Score {chunk['score']:.3f} - {chunk['content'][:100]}...")
            else:
                print("   âš ï¸  No relevant chunks found")
                
        except Exception as e:
            print(f"   âŒ Error: {e}")
    
    # Test 3: Generate full answers
    print("\nğŸ¤– Testing Answer Generation...")
    
    test_request = GenerateResponseRequest(
        question="What is your company's experience with similar RFP projects?",
        question_id="test-question-1",
        project_id="test-project-1",
        use_all_indexes=True
    )
    
    try:
        response = await rag_answer_service.generate_answer(test_request)
        
        print(f"âœ… Answer generated successfully!")
        print(f"   ğŸ“ Response length: {len(response.response)} characters")
        print(f"   ğŸ¯ Confidence: {response.metadata.get('confidence', 'N/A')}")
        print(f"   ğŸ“š Sources: {len(response.sources)} found")
        print(f"   ğŸ”§ Method: {response.metadata.get('search_method', 'N/A')}")
        
        print(f"\nğŸ“„ Generated Answer:")
        print("-" * 40)
        print(response.response[:500] + "..." if len(response.response) > 500 else response.response)
        print("-" * 40)
        
        if response.sources:
            print(f"\nğŸ“š Sources:")
            for source in response.sources[:3]:
                print(f"   ğŸ“‹ {source['fileName']} (Page {source['pageNumber']}) - {source['relevance']}% relevant")
        
    except Exception as e:
        print(f"âŒ Error generating answer: {e}")
    
    # Test 4: Configuration check
    print("\nâš™ï¸  Configuration Summary:")
    print(f"   ğŸ”— Qdrant URL: {rag_answer_service.qdrant_url or 'Not configured'}")
    print(f"   ğŸ”— Azure Endpoint: {rag_answer_service.azure_endpoint or 'Not configured'}")
    print(f"   ğŸ“Š Collection: {rag_answer_service.collection_name}")
    print(f"   ğŸ¯ Max chunks: {rag_answer_service.max_context_chunks}")
    print(f"   ğŸ“ Min similarity: {rag_answer_service.min_similarity_score}")
    
    print("\n" + "=" * 60)
    print("âœ… RAG System Test Completed!")
    
    if not rag_answer_service.qdrant_client:
        print("\nâš ï¸  To enable full RAG functionality:")
        print("   1. Set QDRANT_URL and QDRANT_API_KEY environment variables")
        print("   2. Upload documents to RFP_AI_Collection in Qdrant")
        print("   3. Restart the backend server")
    
    if not rag_answer_service.openai_client:
        print("\nâš ï¸  To enable Azure OpenAI:")
        print("   1. Set AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY")
        print("   2. Restart the backend server")

async def main():
    """Run all RAG tests."""
    await test_rag_system()

if __name__ == "__main__":
    asyncio.run(main())